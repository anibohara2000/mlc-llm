





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ðŸ‘‹ Welcome to MLC LLM &mdash; mlc-llm 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/tabs.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/tabs.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <script type="text/javascript" src="_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Project Overview" href="get_started/project_overview.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://llm.mlc.ai/>Home</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/mlc-ai/mlc-llm>Github</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://discord.gg/9Xpy2HGBuD>Discord Server</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   Other Resources
                 </button>
                 <ul>
                     <li>
                       <a href=https://mlc.ai/>MLC Course</a>
                     </li>
                     <li>
                       <a href=https://blog.mlc.ai/>MLC Blog</a>
                     </li>
                     <li>
                       <a href=https://webllm.mlc.ai/>Web LLM</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  Other Resources
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://mlc.ai/>MLC Course</a>
                     </li>
                     <li>
                       <a href=https://blog.mlc.ai/>MLC Blog</a>
                     </li>
                     <li>
                       <a href=https://webllm.mlc.ai/>Web LLM</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#">
          

          
            
            <img src="_static/mlc-logo-with-text-landscape.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
                <div class="version">
                  0.1.0
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="get_started/project_overview.html">Project Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="get_started/mlc_chat_config.html">Configure MLCChat in JSON</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build and Deploy Apps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deploy/javascript.html">WebLLM and Javascript API</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/rest.html">Rest API</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/cli.html">CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/python.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/ios.html">iOS App and Swift API</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/android.html">Android App</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/ide_integration.html">Code Completion IDE Integration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compile Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="compilation/convert_weights.html">Convert Weights via MLC</a></li>
<li class="toctree-l1"><a class="reference internal" href="compilation/compile_models.html">Compile Model Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="compilation/define_new_models.html">Define New Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="compilation/configure_quantization.html">ðŸš§ Configure Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Prebuilts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="prebuilt_models.html">Model Prebuilts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dependency Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install/tvm.html">Install TVM Unity Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="install/mlc_llm.html">Install MLC LLM Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="install/conda.html">Install Conda</a></li>
<li class="toctree-l1"><a class="reference internal" href="install/gpu.html">GPU Drivers and SDKs</a></li>
<li class="toctree-l1"><a class="reference internal" href="install/emcc.html">Install Wasm Build Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/guideline.html">Community Guideline</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="privacy.html">MLC Chat App Privacy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- mlc-llm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> <span class="br-arrow">></span></li>
        
      <li>ðŸ‘‹ Welcome to MLC LLM</li>
    
    
      
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/mlc-ai/mlc-llm/edit/main/docs/index.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="welcome-to-mlc-llm">
<h1>ðŸ‘‹ Welcome to MLC LLM<a class="headerlink" href="#welcome-to-mlc-llm" title="Permalink to this heading">Â¶</a></h1>
<p><a class="reference external" href="https://discord.gg/9Xpy2HGBuD">Discord</a> | <a class="reference external" href="https://github.com/mlc-ai/mlc-llm">GitHub</a></p>
<p>Machine Learning Compilation for Large Language Models (MLC LLM) is a high-performance universal deployment solution that allows native deployment of any large language models with native APIs with compiler acceleration. The mission of this project is to enable everyone to develop, optimize and deploy AI models natively on everyoneâ€™s devices with ML compilation techniques.</p>
<section id="getting-started">
<span id="get-started"></span><h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading">Â¶</a></h2>
<p>To begin with, try out MLC LLM support for int4-quantized Llama2 7B.
It is recommended to have at least 6GB free VRAM to run it.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Python</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Command Line</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">Web Browser</button><button aria-controls="panel-0-0-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-3" name="0-3" role="tab" tabindex="-1">iOS</button><button aria-controls="panel-0-0-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-4" name="0-4" role="tab" tabindex="-1">Android</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p><strong>Install MLC LLM Python</strong>. <a class="reference internal" href="install/mlc_llm.html"><span class="doc">MLC LLM</span></a> is available via pip.
It is always recommended to install it in an isolated conda virtual environment.</p>
<p><strong>Download pre-quantized weights</strong>. The commands below download the int4-quantized Llama2-7B from HuggingFace:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>lfs<span class="w"> </span>install<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>mkdir<span class="w"> </span>dist/
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/mlc-ai/Llama-2-7b-chat-hf-q4f16_1-MLC<span class="w"> </span><span class="se">\</span>
<span class="w">                                  </span>dist/Llama-2-7b-chat-hf-q4f16_1-MLC
</pre></div>
</div>
<p><strong>Download pre-compiled model library</strong>. The pre-compiled model library is available as below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/mlc-ai/binary-mlc-llm-libs.git<span class="w"> </span>dist/prebuilt_libs
</pre></div>
</div>
<p><strong>Run in Python.</strong> The following Python script showcases the Python API of MLC LLM and its stream capability:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlc_llm</span> <span class="kn">import</span> <span class="n">ChatModule</span>
<span class="kn">from</span> <span class="nn">mlc_llm.callback</span> <span class="kn">import</span> <span class="n">StreamToStdout</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">ChatModule</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;dist/Llama-2-7b-chat-hf-q4f16_1-MLC&quot;</span><span class="p">,</span>
    <span class="n">model_lib_path</span><span class="o">=</span><span class="s2">&quot;dist/prebuilt_libs/Llama-2-7b-chat-hf/Llama-2-7b-chat-hf-q4f16_1-cuda.so&quot;</span>
    <span class="c1"># Vulkan on Linux: Llama-2-7b-chat-hf-q4f16_1-vulkan.so</span>
    <span class="c1"># Metal on macOS: Llama-2-7b-chat-hf-q4f16_1-metal.so</span>
    <span class="c1"># Other platforms: Llama-2-7b-chat-hf-q4f16_1-{backend}.{suffix}</span>
<span class="p">)</span>
<span class="n">cm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;What is the meaning of life?&quot;</span><span class="p">,</span> <span class="n">progress_callback</span><span class="o">=</span><span class="n">StreamToStdout</span><span class="p">(</span><span class="n">callback_interval</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Colab walkthrough.</strong>  A Jupyter notebook on <a class="reference external" href="https://colab.research.google.com/github/mlc-ai/notebooks/blob/main/mlc-llm/tutorial_chat_module_getting_started.ipynb">Colab</a>
is provided with detailed walkthrough of the Python API.</p>
<p><strong>Documentation and tutorial.</strong> Python API reference and its tutorials are <a class="reference external" href="https://llm.mlc.ai/docs/deploy/python.html#api-reference">available online</a>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/mlc-ai/web-data/main/images/mlc-llm/tutorials/python-api.jpg"><img alt="https://raw.githubusercontent.com/mlc-ai/web-data/main/images/mlc-llm/tutorials/python-api.jpg" src="https://raw.githubusercontent.com/mlc-ai/web-data/main/images/mlc-llm/tutorials/python-api.jpg" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-text">MLC LLM Python API</span><a class="headerlink" href="#id1" title="Permalink to this image">Â¶</a></p>
</figcaption>
</figure>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><p><strong>Install MLC LLM</strong>. <a class="reference internal" href="install/mlc_llm.html"><span class="doc">MLC LLM</span></a> is available via pip.
It is always recommended to install it in an isolated conda virtual environment.</p>
<p>For Windows/Linux users, make sure to have latest <a class="reference internal" href="install/gpu.html#vulkan-driver"><span class="std std-ref">Vulkan driver</span></a> installed.</p>
<p><strong>Run in command line</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlc_llm<span class="w"> </span>chat<span class="w"> </span>HF://mlc-ai/Llama-2-7b-chat-hf-q4f16_1-MLC
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><p><a class="reference external" href="https://webllm.mlc.ai/#chat-demo">WebLLM</a>. MLC LLM generates performant code for WebGPU and WebAssembly,
so that LLMs can be run locally in a web browser without server resources.</p>
<p><strong>Download pre-quantized weights</strong>. This step is self-contained in WebLLM.</p>
<p><strong>Download pre-compiled model library</strong>. WebLLM automatically downloads WebGPU code to execute.</p>
<p><strong>Check browser compatibility</strong>. The latest Google Chrome provides WebGPU runtime and <a class="reference external" href="https://webgpureport.org/">WebGPU Report</a> as a useful tool to verify WebGPU capabilities of your browser.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://blog.mlc.ai/img/redpajama/web.gif"><img alt="https://blog.mlc.ai/img/redpajama/web.gif" src="https://blog.mlc.ai/img/redpajama/web.gif" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-text">MLC LLM on Web</span><a class="headerlink" href="#id2" title="Permalink to this image">Â¶</a></p>
</figcaption>
</figure>
</div><div aria-labelledby="tab-0-0-3" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-3" name="0-3" role="tabpanel" tabindex="0"><p><strong>Install MLC Chat iOS</strong>. It is available on AppStore:</p>
<a class="reference external image-reference" href="https://apps.apple.com/us/app/mlc-chat/id6448482937"><img alt="https://developer.apple.com/assets/elements/badges/download-on-the-app-store.svg" src="https://developer.apple.com/assets/elements/badges/download-on-the-app-store.svg" width="135" /></a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Requirement</strong>. Llama2-7B model needs an iOS device with a minimum of 6GB RAM, whereas the RedPajama-3B model runs with at least 4GB RAM.</p>
<p><strong>Tutorial and source code</strong>. The source code of the iOS app is fully <a class="reference external" href="https://github.com/mlc-ai/mlc-llm/tree/main/ios">open source</a>,
and a <a class="reference internal" href="deploy/ios.html"><span class="doc">tutorial</span></a> is included in documentation.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://blog.mlc.ai/img/redpajama/ios.gif"><img alt="https://blog.mlc.ai/img/redpajama/ios.gif" src="https://blog.mlc.ai/img/redpajama/ios.gif" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-text">MLC Chat on iOS</span><a class="headerlink" href="#id3" title="Permalink to this image">Â¶</a></p>
</figcaption>
</figure>
</div><div aria-labelledby="tab-0-0-4" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-4" name="0-4" role="tabpanel" tabindex="0"><p><strong>Install MLC Chat Android</strong>. A prebuilt is available as an APK:</p>
<a class="reference external image-reference" href="https://github.com/mlc-ai/binary-mlc-llm-libs/releases/download/Android/mlc-chat.apk"><img alt="https://seeklogo.com/images/D/download-android-apk-badge-logo-D074C6882B-seeklogo.com.png" src="https://seeklogo.com/images/D/download-android-apk-badge-logo-D074C6882B-seeklogo.com.png" style="width: 135px;" /></a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Requirement</strong>. Llama2-7B model needs a device with a minimum of 6GB RAM, whereas the RedPajama-3B model runs with at least 4GB RAM.
The demo is tested on</p>
<ul class="simple">
<li><p>Samsung S23 with Snapdragon 8 Gen 2 chip</p></li>
<li><p>Redmi Note 12 Pro with Snapdragon 685</p></li>
<li><p>Google Pixel phones</p></li>
</ul>
<p><strong>Tutorial and source code</strong>. The source code of the android app is fully <a class="reference external" href="https://github.com/mlc-ai/mlc-llm/tree/main/android">open source</a>,
and a <a class="reference internal" href="deploy/android.html"><span class="doc">tutorial</span></a> is included in documentation.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://blog.mlc.ai/img/android/android-recording.gif"><img alt="https://blog.mlc.ai/img/android/android-recording.gif" src="https://blog.mlc.ai/img/android/android-recording.gif" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-text">MLC LLM on Android</span><a class="headerlink" href="#id4" title="Permalink to this image">Â¶</a></p>
</figcaption>
</figure>
</div></div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="get_started/project_overview.html" class="btn btn-neutral float-right" title="Project Overview" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>

<div id="button" class="backtop"><img src="_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">Â© 2023 MLC LLM</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote"> </div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>